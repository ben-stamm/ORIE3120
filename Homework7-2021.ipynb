{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vh1RaeAXoje4"
   },
   "source": [
    "# **Homework 7**\n",
    "\n",
    "Due Monday April 12, 2021 at 11:59pm\n",
    "Submit an ipynb file to gradescope.\n",
    "Remember to also submit Recitation 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVFcBbWnskHG"
   },
   "source": [
    "Load packages we will use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9vXs8qqxsT-X"
   },
   "outputs": [],
   "source": [
    "#math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#dataframes\n",
    "import pandas as pd\n",
    "\n",
    "#ploting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#regression tools\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.020\n",
      "Model:                            OLS   Adj. R-squared:                 -0.034\n",
      "Method:                 Least Squares   F-statistic:                    0.3725\n",
      "Date:                Mon, 12 Apr 2021   Prob (F-statistic):              0.549\n",
      "Time:                        20:13:02   Log-Likelihood:                -31.195\n",
      "No. Observations:                  20   AIC:                             66.39\n",
      "Df Residuals:                      18   BIC:                             68.38\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1381      0.280      0.493      0.628      -0.451       0.727\n",
      "x             -0.1414      0.232     -0.610      0.549      -0.628       0.345\n",
      "==============================================================================\n",
      "Omnibus:                        5.015   Durbin-Watson:                   1.389\n",
      "Prob(Omnibus):                  0.081   Jarque-Bera (JB):                3.153\n",
      "Skew:                          -0.951   Prob(JB):                        0.207\n",
      "Kurtosis:                       3.410   Cond. No.                         1.38\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "confidence interval for beta_1 is (-0.628060376375546, 0.34528454869223246)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bls24\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# This function creates some data, fits a linear regression model Y=beta0 + beta1*X,\n",
    "# and then prints out the model summary and the lower and upper bounds of a 95% confidence\n",
    "# interval on beta_1.\n",
    "df = pd.DataFrame()\n",
    "n = 20\n",
    "p = 2\n",
    "df['x'] = np.random.randn(n)\n",
    "y = np.random.randn(n)\n",
    "df = sm.add_constant(df)\n",
    "model = sm.OLS(y,df).fit()\n",
    "print(model.summary())\n",
    "conf_int = model.conf_int().loc['x']\n",
    "lower = conf_int[0]\n",
    "upper = conf_int[1]\n",
    "print(f'confidence interval for beta_1 is {lower,upper}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1A.\n",
    "What are the values of `beta_0` and `beta_1` used to generate the data in the cell above?\n",
    "Suppose the 95% confidence interval returned for beta_1 is [-0.36, 0.48], does this contain `beta_1`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "* beta_0 coefficient: -.3771\n",
    "* beta_1 coefficient: -.1489\n",
    "* YES, the 95% confidence interval specified above does contain beta_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': -1.026528290329942,\n",
       " 'upper': 0.3475162608887538,\n",
       " 'beta1': -0.3395060147205941}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function takes the same functionality and the previous cell,\n",
    "# but wraps it in a function and returns the result as a dictionary\n",
    "def example_data():\n",
    "    df = pd.DataFrame()\n",
    "    n = 20\n",
    "    p = 2\n",
    "    df['x'] = np.random.randn(n)\n",
    "    y = np.random.randn(n)\n",
    "    df = sm.add_constant(df)\n",
    "    model = sm.OLS(y,df).fit()\n",
    "    conf_int = model.conf_int().loc['x']\n",
    "    coef = model.params.loc['x']\n",
    "    lower = conf_int[0]\n",
    "    upper = conf_int[1]\n",
    "    #beta_1 = coef[1]\n",
    "    return {'lower' : lower, 'upper' : upper, 'beta1':coef}#, 'model_check':model.params}\n",
    "\n",
    "example_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>beta1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.065237</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.333075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.367412</td>\n",
       "      <td>1.157405</td>\n",
       "      <td>0.394997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.235562</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0.224726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.318996</td>\n",
       "      <td>0.551429</td>\n",
       "      <td>0.116216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.808923</td>\n",
       "      <td>0.282077</td>\n",
       "      <td>-0.263423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lower     upper     beta1\n",
       "0 -0.065237  0.731387  0.333075\n",
       "1 -0.367412  1.157405  0.394997\n",
       "2 -0.235562  0.685014  0.224726\n",
       "3 -0.318996  0.551429  0.116216\n",
       "4 -0.808923  0.282077 -0.263423"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This runs the example_data function many times to generate many independent datasets,\n",
    "# all using the same values for beta_0 and beta_1. From each dataset, we generate a 95% confidence\n",
    "# interval for beta_1 and put it into the dataframe conf_int\n",
    "conf_int = pd.DataFrame(columns=['lower','upper'])\n",
    "for i in range(100):\n",
    "    conf_int = conf_int.append(example_data(),ignore_index=True)\n",
    "conf_int.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1B\n",
    "\n",
    "What is the theoretical probability that beta_1 should be contained between the lower and upper bound returned by example_data()? (Though we discussed this in ORIE 3120, you can also answer this based on what you learned about confidence intervals in ENGRD 2700.)\n",
    "\n",
    "Write code to calculate how often it happens in the data that you generated. In what fraction of the records in conf_int does it happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = list(conf_int[\"lower\"])\n",
    "upper = list(conf_int[\"upper\"])\n",
    "beta1 = list(conf_int[\"beta1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(lower)):\n",
    "    if beta1[i] >= lower[i] and beta1[i] <= upper[i]:\n",
    "        count+=1\n",
    "print(count*1.0/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strangely, when I calculate the fraction of the records in conf_int that beta1 is contained between the lower and upper bound, I get an answer of 100% of the time, which differs from the expected result of 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "We have data from an online food delivery service in `PurchaseVsPrice.csv`. This data contains data from an experiment in which the price of a meal was varied between \\\\$0 and \\\\$20 to customers that had the company's mobile app installed on their phone.  For each price offered, we see whether or not the meal was purchased, where Y=1 means a purchase was made and Y=0 means it was not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2A. \n",
    "Load the data into a dataframe and fit a logistic regression model of the form P(Y=1|X) = L(beta_0+beta_1*X). Here, Y=1 indicates purchase, Y=0 indicates no purchase, and X is the price. What are the fitted values of beta_0 and beta_1?  Are these parameter statistically significant at the 95\\% level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.669310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.268658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.370370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.076877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.341077</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       price  purchase\n",
       "0   0.669310         1\n",
       "1   5.268658         1\n",
       "2  17.370370         0\n",
       "3   7.076877         1\n",
       "4   3.341077         1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('PurchaseVsPrice.csv') #QUESTION -- what does the Y=1 mean here? Am I building this model correctly?\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.387791\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "X = df[\"price\"]\n",
    "Y = df[\"purchase\"]\n",
    "X = sm.add_constant(X)\n",
    "model = sm.Logit(Y,X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>purchase</td>     <th>  No. Observations:  </th>  <td>100000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td> 99998</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 12 Apr 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.4229</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:13:04</td>     <th>  Log-Likelihood:    </th> <td> -38779.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -67200.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    3.0262</td> <td>    0.021</td> <td>  144.250</td> <td> 0.000</td> <td>    2.985</td> <td>    3.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>price</th> <td>   -0.3861</td> <td>    0.002</td> <td> -167.361</td> <td> 0.000</td> <td>   -0.391</td> <td>   -0.382</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               purchase   No. Observations:               100000\n",
       "Model:                          Logit   Df Residuals:                    99998\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Mon, 12 Apr 2021   Pseudo R-squ.:                  0.4229\n",
       "Time:                        20:13:04   Log-Likelihood:                -38779.\n",
       "converged:                       True   LL-Null:                       -67200.\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          3.0262      0.021    144.250      0.000       2.985       3.067\n",
       "price         -0.3861      0.002   -167.361      0.000      -0.391      -0.382\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beta_0 is 3.03 and beta_1 is -.386. Both of these parameters are statistically significant at the 95% level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2B.\n",
    "Using a pandas groupby and the round function, create a dataframe that consists of:\n",
    "* the price rounded to the nearest 0.1 dollar\n",
    "* the fraction of time that the consumer purchased the meal for each rounded price\n",
    "We call this second bullet point the \"empirical probability of purchase\".\n",
    "\n",
    "Then plot the empirical probability of purchase vs. the rounded price as a collection of dots.\n",
    "\n",
    "Also, use your fitted logistic regression model to predict what the probability of purchase should be at each rounded price and plot this as a line.  \n",
    "\n",
    "You should see that both the empirical probability of purchase and your prediction decrease with the price, but that your prediction has a different shape.  In particular, your prediction should be larger than the empirical probability of a purchase at low prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>empirical probability of purchase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.789062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.774947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.822857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.793173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.790123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  price empirical probability of purchase\n",
       "                                         \n",
       "0   0.0                          0.789062\n",
       "1   0.1                          0.774947\n",
       "2   0.2                          0.822857\n",
       "3   0.3                          0.793173\n",
       "4   0.4                          0.790123"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_df = df.round(1)\n",
    "grouped_df = rounded_df.groupby('price').agg({\"purchase\":[np.sum,'count']})\n",
    "grouped_df = grouped_df.reset_index()\n",
    "grouped_df['empirical probability of purchase'] = grouped_df['purchase']['sum'] / grouped_df[\"purchase\"]['count']\n",
    "grouped_df = grouped_df[['price','empirical probability of purchase']]\n",
    "grouped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_value = grouped_df['price'].values\n",
    "x_value_constant = sm.add_constant(x_value)\n",
    "y_value = grouped_df['empirical probability of purchase']\n",
    "model_line = model.predict(x_value_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'empirical probability')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_value,y_value) #QUESTION -- how do I plot my logistic model on this graph/use it for predictions?\n",
    "plt.scatter(x_value, model_line)\n",
    "#plt.plot(x_value,model_line,c='red')\n",
    "plt.xlabel(\"price\")\n",
    "plt.ylabel(\"empirical probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2C.\n",
    "To better explain the data, we are going to fit a different model. We are going to assume that the data was generated from the model P(Y=1|X) = q*L(beta_0 + beta_1 * x), for some parameters q, beta_0, and beta_1.  This is because the customers were offered the product with a push notification, and only a fraction q of the customers actually looked at their phone when the push notification was sent. For those that ignored the push notification, the price has no impact and they didn't purchase a meal.\n",
    "\n",
    "We will then estimate these three parameters via maximum likelihood estimation.  As a first step, write down a formula for the likelihood. This is clearest when done in latex. Some examples are given below to help you.\n",
    "\n",
    "Your answer should depend on:\n",
    "* $q$\n",
    "* $\\beta_0$\n",
    "* $\\beta_1$\n",
    "* $y_i$ (whether the i-th customer in the dataset mode a purchase or not)\n",
    "* $x_i$ (the price shown to the i-th customer in the dataset)\n",
    "\n",
    "Then, write down the natural logarithm of the likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula for likelihood\n",
    "\n",
    "$\\prod_{i=1}^n (q*L(\\beta_0+\\beta_1*x_i))(X_{i,1} , ... , X_{i,((q*L(\\beta_0+\\beta_1*x_i)))} )^{y_i} (1-(q*L(\\beta_0+\\beta_1*x_i))(X_{i,1} , ... , X_{i,(q*L(\\beta_0+\\beta_1*x_i))}))^{1-y_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural Log of the likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sum_{i=1}^n y_i * \\ln( (q*L(\\beta_0+\\beta_1*x_i))(X_{i,1} , ... , X_{i,((q*L(\\beta_0+\\beta_1*x_i)))} ) + (1-y_i) * \\ln((1-(q*L(\\beta_0+\\beta_1*x_i))(X_{i,1} , ... , X_{i,(q*L(\\beta_0+\\beta_1*x_i))})) )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of using latex in a python notebook\n",
    "\n",
    "* Writing a product: $\\prod_{i=1}^n a_i$\n",
    "* Writing a sum: $\\sum_{i=1}^n b_i$\n",
    "* Writing greek letters: $\\beta_j$, $\\alpha_5$, $\\gamma_2$\n",
    "* Raising something to a power: $a^{b+c}$\n",
    "* Putting something in a subscript: $z_k$\n",
    "* Taking the log: $\\log(5)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D\n",
    "Write a function called `log_likelihood` that calculates the log likelihood. It should take as input `q`, `beta_0`, and `beta_1` and it should also use the data that you loaded above in part A.  To help you, the following code will compute the logistic function on each entry in a Pandas Series and return the result as another series.  Calculate the log likelihood at `q`=0.5, `beta_0` = 1, and `beta_1` = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.669310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.268658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.370370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.076877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.341077</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       price  purchase\n",
       "0   0.669310         1\n",
       "1   5.268658         1\n",
       "2  17.370370         0\n",
       "3   7.076877         1\n",
       "4   3.341077         1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L(x):\n",
    "    return 1./(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(q,beta_0,beta_1):\n",
    "    first_term = (df[\"purchase\"]) * np.log(q*L(beta_0 + beta_1 * df['price']))\n",
    "    second_term = (1-df[\"purchase\"]) * np.log(1 - (q*L(beta_0 + beta_1 * df['price'])))\n",
    "    answer = first_term + second_term\n",
    "    return(answer.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-70358.77854754729"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood(.5,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2E\n",
    "\n",
    "To find the maximum likelihood estimate, we will use random search. You may find code from Recitation 8 helpful here, where we used random search for a different purpose.\n",
    "\n",
    "To do this, create a new dataframe called `newdata` that contains 1000 records and these three fields, generated at random:\n",
    "* Draw `q` from a uniform between 0 and 1\n",
    "* Draw `beta_0` from a uniform between 0 and 20\n",
    "* Draw `beta_1` from a uniform between -2 and 0\n",
    "\n",
    "Then, add a new field called `log_likelihood` and for each record set it equal to the value of your `log_likelihood` function evaluated at the `q`, `beta_0`, and `beta_1` in the other fields in this record.  To help you, one way to create new entries one record at a time using iterrows() (which you used in a previous recitation) is below.\n",
    "\n",
    "Then, find the record in `newdata` with the largest value for `log_likelihood`.  Create values `mle_q`, `mle_beta0`, and `mle_beta1` equal to the values of the three parameters in this record. What are these values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To help you, here is some example code that generates a dataframe with some random values, \n",
    "# and then creates a new field that has the result of a function evaluated on the other fields.\n",
    "newdata = pd.DataFrame()\n",
    "N = 1000\n",
    "np.random.seed(10)\n",
    "newdata['example0'] = np.random.uniform(-2,4,N) # Generate some random data\n",
    "newdata['example1'] = np.random.uniform(-2,4,N) # Generate some random data\n",
    "\n",
    "def fn(x,y):\n",
    "    if x<y:\n",
    "        return 5\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "newdata['example2']=0\n",
    "for index, row in newdata.iterrows():\n",
    "    newdata.loc[index,'example2'] = fn(row['example1'],row['example2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = pd.DataFrame()\n",
    "N = 1000\n",
    "np.random.seed(10)\n",
    "newdata['q'] = np.random.uniform(0,1,N)\n",
    "newdata['beta_0'] = np.random.uniform(0,20,N) # Generate some random data\n",
    "newdata['beta_1'] = np.random.uniform(-2,0,N) # Generate some random data\n",
    "\n",
    "newdata['log_likelihood'] = 0\n",
    "for index, row in newdata.iterrows():\n",
    "    newdata.loc[index, 'log_likelihood'] = log_likelihood(row['q'],row['beta_0'],row['beta_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q</th>\n",
       "      <th>beta_0</th>\n",
       "      <th>beta_1</th>\n",
       "      <th>log_likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>0.800694</td>\n",
       "      <td>10.307195</td>\n",
       "      <td>-1.032002</td>\n",
       "      <td>-34933.048855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            q     beta_0    beta_1  log_likelihood\n",
       "511  0.800694  10.307195 -1.032002   -34933.048855"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_max_likelihood = newdata[newdata['log_likelihood'] == newdata['log_likelihood'].max()]\n",
    "df_max_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2F\n",
    "For each rounded price that you plotted against in 2B, plot:\n",
    "* the empirical purchase probability, as a dot\n",
    "* the probability of a purchase according to the model that you fit using maximum likelihood estimation, as a line\n",
    "    \n",
    "You should see that the probability of purchase according to maximum likelihood estimation fits the data much better than your earlier logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_purchase = .800694 * L(10.307195-1.032002*x_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16e9e4f79b0>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_value,y_value,'.')\n",
    "plt.plot(x_value,probability_purchase, '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lTYRBSekIKxW"
   },
   "source": [
    "## Problem 3: Multiple Linear Regression and Understanding p-values\n",
    "\n",
    "In this problem, we will try to predict the energy used by appliances based on the temperature in and humidity of various rooms of a house and the outside weather conditions. We will use 'energydata.csv'. The full dataset and descriptions of the columns can be found [here](http://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction#). Please use the data posted on the website for analysis as we have removed some columns and filtered the data. \n",
    "\n",
    "a. Begin by loading the data. Display the names of the columns and the first 5 rows. (It is often a good idea to display column names and a few rows to make sure you understand what is included in the data you imported.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OElwnXoHjCm7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Appliances</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>T2</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>T3</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>T4</th>\n",
       "      <th>RH_4</th>\n",
       "      <th>T5</th>\n",
       "      <th>...</th>\n",
       "      <th>T8</th>\n",
       "      <th>RH_8</th>\n",
       "      <th>T9</th>\n",
       "      <th>RH_9</th>\n",
       "      <th>T_out</th>\n",
       "      <th>Press_mm_hg</th>\n",
       "      <th>RH_out</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Tdewpoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>47.596667</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.566667</td>\n",
       "      <td>17.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>18.20</td>\n",
       "      <td>48.900000</td>\n",
       "      <td>17.033333</td>\n",
       "      <td>45.530</td>\n",
       "      <td>6.6</td>\n",
       "      <td>733.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>21.390000</td>\n",
       "      <td>44.560000</td>\n",
       "      <td>20.790000</td>\n",
       "      <td>43.863333</td>\n",
       "      <td>20.20</td>\n",
       "      <td>45.663333</td>\n",
       "      <td>20.633333</td>\n",
       "      <td>46.790000</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.39</td>\n",
       "      <td>51.163333</td>\n",
       "      <td>16.890000</td>\n",
       "      <td>45.700</td>\n",
       "      <td>5.3</td>\n",
       "      <td>736.9</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>20.100000</td>\n",
       "      <td>46.363333</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>20.29</td>\n",
       "      <td>45.590000</td>\n",
       "      <td>19.760000</td>\n",
       "      <td>46.590000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.10</td>\n",
       "      <td>54.290000</td>\n",
       "      <td>17.100000</td>\n",
       "      <td>49.260</td>\n",
       "      <td>5.0</td>\n",
       "      <td>739.9</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>46.766667</td>\n",
       "      <td>19.033333</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>20.00</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>20.133333</td>\n",
       "      <td>44.700000</td>\n",
       "      <td>18.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>18.50</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>17.050000</td>\n",
       "      <td>45.245</td>\n",
       "      <td>6.4</td>\n",
       "      <td>743.3</td>\n",
       "      <td>86.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>20.066667</td>\n",
       "      <td>42.833333</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>42.418182</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.700000</td>\n",
       "      <td>19.260000</td>\n",
       "      <td>42.560000</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.60</td>\n",
       "      <td>45.790000</td>\n",
       "      <td>17.100000</td>\n",
       "      <td>43.260</td>\n",
       "      <td>6.5</td>\n",
       "      <td>744.2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Appliances         T1       RH_1         T2       RH_2     T3       RH_3  \\\n",
       "0          60  19.890000  47.596667  19.200000  44.790000  19.79  44.730000   \n",
       "1          40  21.390000  44.560000  20.790000  43.863333  20.20  45.663333   \n",
       "2          50  20.100000  46.363333  19.500000  44.790000  20.29  45.590000   \n",
       "3          50  19.890000  46.766667  19.033333  44.500000  20.00  44.790000   \n",
       "4          60  20.066667  42.833333  19.000000  42.418182  19.79  44.700000   \n",
       "\n",
       "          T4       RH_4         T5  ...     T8       RH_8         T9    RH_9  \\\n",
       "0  19.000000  45.566667  17.166667  ...  18.20  48.900000  17.033333  45.530   \n",
       "1  20.633333  46.790000  19.200000  ...  19.39  51.163333  16.890000  45.700   \n",
       "2  19.760000  46.590000  18.500000  ...  19.10  54.290000  17.100000  49.260   \n",
       "3  20.133333  44.700000  18.033333  ...  18.50  49.000000  17.050000  45.245   \n",
       "4  19.260000  42.560000  17.600000  ...  18.60  45.790000  17.100000  43.260   \n",
       "\n",
       "   T_out  Press_mm_hg  RH_out  Windspeed  Visibility  Tdewpoint  \n",
       "0    6.6        733.5    92.0        7.0        63.0        5.3  \n",
       "1    5.3        736.9    92.0        6.0        22.0        4.1  \n",
       "2    5.0        739.9    91.0        5.0        40.0        3.6  \n",
       "3    6.4        743.3    86.0        5.0        40.0        4.2  \n",
       "4    6.5        744.2    75.0        7.0        29.0        2.3  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code Here\n",
    "energy_df = pd.read_csv('energydata.csv')\n",
    "energy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j_88d3h1Krk4"
   },
   "source": [
    "b. Use sm.OLS().fit to build a linear model. Print the model summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhb1cOxILDK9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Appliances</td>    <th>  R-squared:         </th> <td>   0.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 12 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>2.07e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:13:05</td>     <th>  Log-Likelihood:    </th> <td> -3282.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   549</td>      <th>  AIC:               </th> <td>   6616.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   524</td>      <th>  BIC:               </th> <td>   6723.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    24</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>       <td>    1.9536</td> <td>  600.978</td> <td>    0.003</td> <td> 0.997</td> <td>-1178.669</td> <td> 1182.576</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>T1</th>          <td>   -2.1323</td> <td>   11.368</td> <td>   -0.188</td> <td> 0.851</td> <td>  -24.464</td> <td>   20.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RH_1</th>        <td>   12.9817</td> <td>    4.888</td> <td>    2.656</td> <td> 0.008</td> <td>    3.378</td> <td>   22.585</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>T2</th>          <td>  -28.2677</td> <td>   10.099</td> <td>   -2.799</td> <td> 0.005</td> <td>  -48.108</td> <td>   -8.427</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RH_2</th>        <td>  -15.1415</td> <td>    5.216</td> <td>   -2.903</td> <td> 0.004</td> <td>  -25.388</td> <td>   -4.895</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>T3</th>          <td>   32.3508</td> <td>    6.693</td> <td>    4.833</td> <td> 0.000</td> <td>   19.202</td> <td>   45.499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RH_3</th>        <td>    6.2454</td> <td>    4.273</td> <td>    1.462</td> <td> 0.144</td> <td>   -2.149</td> <td>   14.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>T4</th>          <td>   11.7059</td> <td>    5.939</td> <td>    1.971</td> <td> 0.049</td> <td>    0.038</td> <td>   23.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RH_4</th>        <td>    7.6966</td> <td>    3.940</td> <td>    1.953</td> <td> 0.051</td> <td>   -0.044</td> <td>   15.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>T5</th>          <td>  -10.0444</td> <td>    7.698</td> <td>   -1.305</td> <td> 0.193</td> <td>  -25.168</td> <td>    5.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RH_5</th>        <td>    0.5142</td> <td>    0.632</td> <td>    0.814</td> <td> 0.416</td> <td>   -0.726</td> <td>    1.755</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>T6</th>          <td>    9.1660</td> <td>    4.135</td> <td>    2.217</td> <td> 0.027</td> <td>    1.044</td> <td>   17.288</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RH_6</th>        <td>    0.4448</td> <td>    0.439</td> <td>    1.013</td> <td> 0.312</td> <td>   -0.418</td> <td>    1.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>T7</th>          <td>  -15.2589</td> <td>    8.119</td> <td>   -1.879</td> <td> 0.061</td> <td>  -31.209</td> <td>    0.691</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RH_7</th>        <td>   -1.7082</td> <td>    2.695</td> <td>   -0.634</td> <td> 0.527</td> <td>   -7.003</td> <td>    3.587</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>T8</th>          <td>    7.0290</td> <td>    5.958</td> <td>    1.180</td> <td> 0.239</td> <td>   -4.675</td> <td>   18.733</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RH_8</th>        <td>   -6.0909</td> <td>    2.354</td> <td>   -2.588</td> <td> 0.010</td> <td>  -10.715</td> <td>   -1.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>T9</th>          <td>    1.1775</td> <td>   11.184</td> <td>    0.105</td> <td> 0.916</td> <td>  -20.793</td> <td>   23.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RH_9</th>        <td>   -2.2504</td> <td>    2.723</td> <td>   -0.826</td> <td> 0.409</td> <td>   -7.600</td> <td>    3.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>T_out</th>       <td>  -12.0544</td> <td>    9.313</td> <td>   -1.294</td> <td> 0.196</td> <td>  -30.349</td> <td>    6.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Press_mm_hg</th> <td>    0.1607</td> <td>    0.682</td> <td>    0.236</td> <td> 0.814</td> <td>   -1.178</td> <td>    1.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RH_out</th>      <td>   -1.6528</td> <td>    1.937</td> <td>   -0.853</td> <td> 0.394</td> <td>   -5.458</td> <td>    2.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Windspeed</th>   <td>    2.8774</td> <td>    2.128</td> <td>    1.352</td> <td> 0.177</td> <td>   -1.303</td> <td>    7.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Visibility</th>  <td>   -0.1211</td> <td>    0.320</td> <td>   -0.378</td> <td> 0.706</td> <td>   -0.750</td> <td>    0.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tdewpoint</th>   <td>    2.2306</td> <td>    8.939</td> <td>    0.250</td> <td> 0.803</td> <td>  -15.330</td> <td>   19.792</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>435.840</td> <th>  Durbin-Watson:     </th> <td>   1.918</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>7322.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 3.465</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>19.495</td>  <th>  Cond. No.          </th> <td>1.11e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.11e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Appliances   R-squared:                       0.163\n",
       "Model:                            OLS   Adj. R-squared:                  0.124\n",
       "Method:                 Least Squares   F-statistic:                     4.247\n",
       "Date:                Mon, 12 Apr 2021   Prob (F-statistic):           2.07e-10\n",
       "Time:                        20:13:05   Log-Likelihood:                -3282.8\n",
       "No. Observations:                 549   AIC:                             6616.\n",
       "Df Residuals:                     524   BIC:                             6723.\n",
       "Df Model:                          24                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "const           1.9536    600.978      0.003      0.997   -1178.669    1182.576\n",
       "T1             -2.1323     11.368     -0.188      0.851     -24.464      20.200\n",
       "RH_1           12.9817      4.888      2.656      0.008       3.378      22.585\n",
       "T2            -28.2677     10.099     -2.799      0.005     -48.108      -8.427\n",
       "RH_2          -15.1415      5.216     -2.903      0.004     -25.388      -4.895\n",
       "T3             32.3508      6.693      4.833      0.000      19.202      45.499\n",
       "RH_3            6.2454      4.273      1.462      0.144      -2.149      14.640\n",
       "T4             11.7059      5.939      1.971      0.049       0.038      23.373\n",
       "RH_4            7.6966      3.940      1.953      0.051      -0.044      15.438\n",
       "T5            -10.0444      7.698     -1.305      0.193     -25.168       5.079\n",
       "RH_5            0.5142      0.632      0.814      0.416      -0.726       1.755\n",
       "T6              9.1660      4.135      2.217      0.027       1.044      17.288\n",
       "RH_6            0.4448      0.439      1.013      0.312      -0.418       1.308\n",
       "T7            -15.2589      8.119     -1.879      0.061     -31.209       0.691\n",
       "RH_7           -1.7082      2.695     -0.634      0.527      -7.003       3.587\n",
       "T8              7.0290      5.958      1.180      0.239      -4.675      18.733\n",
       "RH_8           -6.0909      2.354     -2.588      0.010     -10.715      -1.467\n",
       "T9              1.1775     11.184      0.105      0.916     -20.793      23.148\n",
       "RH_9           -2.2504      2.723     -0.826      0.409      -7.600       3.099\n",
       "T_out         -12.0544      9.313     -1.294      0.196     -30.349       6.240\n",
       "Press_mm_hg     0.1607      0.682      0.236      0.814      -1.178       1.500\n",
       "RH_out         -1.6528      1.937     -0.853      0.394      -5.458       2.152\n",
       "Windspeed       2.8774      2.128      1.352      0.177      -1.303       7.058\n",
       "Visibility     -0.1211      0.320     -0.378      0.706      -0.750       0.508\n",
       "Tdewpoint       2.2306      8.939      0.250      0.803     -15.330      19.792\n",
       "==============================================================================\n",
       "Omnibus:                      435.840   Durbin-Watson:                   1.918\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7322.532\n",
       "Skew:                           3.465   Prob(JB):                         0.00\n",
       "Kurtosis:                      19.495   Cond. No.                     1.11e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.11e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code Here\n",
    "X = energy_df.iloc[:,1:]\n",
    "Y = energy_df[\"Appliances\"]\n",
    "X = sm.add_constant(X)\n",
    "lin_model = sm.OLS(Y,X).fit()\n",
    "lin_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M74MjfSmi2Pj"
   },
   "source": [
    "c. Which inputs are significant at the $\\alpha=0.05$ level?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vtPzFTI8tMrA"
   },
   "source": [
    "Ans: RH_1, T2, RH_2, T3, T4, T6, RH_8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vPBHJSzfL48q"
   },
   "source": [
    "d. You decide you want a model with only 5 features. Build a new model with the five features that had the smallest p-values in the previous model. Which features do you select?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J7y3TyNouXm9"
   },
   "outputs": [],
   "source": [
    "#Code Here\n",
    "features = ['RH_1', 'T2', 'RH_2', 'T3', 'RH_8'] #QUESTION -- SHOULD I KEEP THE CONSTANT ?\n",
    "X = X[features]\n",
    "new_model = sm.OLS(Y, X).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RmULtXOXxzi8"
   },
   "source": [
    "Ans: RH_1, T2, RH_2, T3, RH_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Appliances</td>    <th>  R-squared (uncentered):</th>      <td>   0.489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.484</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   104.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 12 Apr 2021</td> <th>  Prob (F-statistic):</th>          <td>6.10e-77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:13:05</td>     <th>  Log-Likelihood:    </th>          <td> -3308.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   549</td>      <th>  AIC:               </th>          <td>   6626.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   544</td>      <th>  BIC:               </th>          <td>   6648.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RH_1</th> <td>   19.6565</td> <td>    3.124</td> <td>    6.293</td> <td> 0.000</td> <td>   13.520</td> <td>   25.792</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>T2</th>   <td>  -16.2112</td> <td>    4.918</td> <td>   -3.297</td> <td> 0.001</td> <td>  -25.871</td> <td>   -6.551</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RH_2</th> <td>  -13.8212</td> <td>    3.091</td> <td>   -4.472</td> <td> 0.000</td> <td>  -19.892</td> <td>   -7.750</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>T3</th>   <td>   15.3860</td> <td>    4.516</td> <td>    3.407</td> <td> 0.001</td> <td>    6.515</td> <td>   24.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RH_8</th> <td>   -3.5040</td> <td>    1.323</td> <td>   -2.649</td> <td> 0.008</td> <td>   -6.103</td> <td>   -0.905</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>465.987</td> <th>  Durbin-Watson:     </th> <td>   1.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>9015.299</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 3.771</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>21.364</td>  <th>  Cond. No.          </th> <td>    135.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:             Appliances   R-squared (uncentered):                   0.489\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.484\n",
       "Method:                 Least Squares   F-statistic:                              104.1\n",
       "Date:                Mon, 12 Apr 2021   Prob (F-statistic):                    6.10e-77\n",
       "Time:                        20:13:05   Log-Likelihood:                         -3308.2\n",
       "No. Observations:                 549   AIC:                                      6626.\n",
       "Df Residuals:                     544   BIC:                                      6648.\n",
       "Df Model:                           5                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "RH_1          19.6565      3.124      6.293      0.000      13.520      25.792\n",
       "T2           -16.2112      4.918     -3.297      0.001     -25.871      -6.551\n",
       "RH_2         -13.8212      3.091     -4.472      0.000     -19.892      -7.750\n",
       "T3            15.3860      4.516      3.407      0.001       6.515      24.257\n",
       "RH_8          -3.5040      1.323     -2.649      0.008      -6.103      -0.905\n",
       "==============================================================================\n",
       "Omnibus:                      465.987   Durbin-Watson:                   1.883\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             9015.299\n",
       "Skew:                           3.771   Prob(JB):                         0.00\n",
       "Kurtosis:                      21.364   Cond. No.                         135.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw07.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
